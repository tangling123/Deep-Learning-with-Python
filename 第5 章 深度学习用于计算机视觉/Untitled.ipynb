{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1198e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载带有预训练权重的VGG16网络\n",
    "from tensorflow.keras.applications.vgg16 import VGG16 \n",
    "\n",
    "model = VGG16(weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f8cc057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#为VGG16网络模型预处理一章输入图像\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "import numpy as np\n",
    " \n",
    "img_path = 'C:\\\\Users\\\\hp-pc\\\\ML\\\\cat_100.jpg' \n",
    "#图像的本地路径\n",
    "img = image.load_img(img_path, target_size = (224, 224))  #读取图像并调整大小\n",
    "\n",
    "x = image.img_to_array(img) #将img图像转换为numpy数组 (224, 224, 3)\n",
    "x = np.expand_dims(x, axis = 0) #将x转换为(1, 224, 224, 3)的数组\n",
    "x = preprocess_input(x) #预处理输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2901db9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [[('n03958227', 'plastic_bag', 0.24324383), ('n02123045', 'tabby', 0.22490391), ('n02124075', 'Egyptian_cat', 0.0793175), ('n02123159', 'tiger_cat', 0.06541321), ('n02123394', 'Persian_cat', 0.039460253)]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp-pc\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "#在图像上运行预训练的VGG16网络，并且将预测向量解码为可读的模式\n",
    "preds = model.predict(x)\n",
    "\n",
    "print('Predicted:', decode_predictions(preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "771d23a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "728"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4fc9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#应用Grad_CAM算法\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution() \n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "african_elephant_output = model.output[: 728] \n",
    "\n",
    "last_conv_layer = model.get_layer('block5_conv3') \n",
    "\n",
    "grads = K.gradients(african_elephant_output, last_conv_layer.output)[0] \n",
    "\n",
    "pooled_grads = K.mean(grads, axis = (0, 1, 2)) \n",
    "\n",
    "iterate = K.function([model.input], [pooled_grads, last_conv_layer.output[0]])\n",
    "\n",
    "\n",
    "pooled_grads_value, conv_layer_output_value = iterate([x]) \n",
    "l = len(conv_layer_output_value)\n",
    "\n",
    "for i in range(512):\n",
    "    conv_layer_output_value[:, :, i] *= pooled_grads_value[i]\n",
    "    \n",
    "heatmap = np.mean(conv_layer_output_value, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64c94b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20d5e5a84c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#热力图后处理\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "plt.matshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c06bbaa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
    "\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "\n",
    "superimposed_img = heatmap * 0.4 + img\n",
    "\n",
    "cv2.imwrite('C:\\\\Users\\\\hp-pc\\\\ML\\\\cat_cam.jpg' , superimposed_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2c6c82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
